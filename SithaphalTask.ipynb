{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz\n",
        "!pip install PyMuPDF\n",
        "!pip install pdfplumber\n",
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK4Elm1BMVMy",
        "outputId": "27cff83a-1046-40d0-e916-0470a78ceeba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (7.1.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.13.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (6.4.5)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (4.12.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.4.2)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.3)\n",
            "Requirement already satisfied: traits>=6.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.4.3)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.16.1)\n",
            "Requirement already satisfied: acres in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.2.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.28)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (5.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.32.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.12.14)\n",
            "Collecting PyMuPDF\n",
            "  Using cached pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Using cached pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "Installing collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.1\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RomGST-BMLiI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import pdfplumber\n",
        "from colorama import Fore, Style"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_text_and_tables(pdf_file, page_index):\n",
        "    \"\"\"\n",
        "    Extracts text and tables from the specified page of the PDF.\n",
        "\n",
        "    Args:\n",
        "        pdf_file (str): Path to the PDF file.\n",
        "        page_index (int): Page index (0-based).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Extracted text (str) and tables (list of lists).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            if not (0 <= page_index < len(pdf.pages)):\n",
        "                return None, None\n",
        "            page = pdf.pages[page_index]\n",
        "            text = page.extract_text()\n",
        "            tables = page.extract_tables()\n",
        "            return text, tables\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error extracting text and tables: {e}\" + Style.RESET_ALL)\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "0-oMsJPFMtyt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images_from_page(pdf_file, page_index, output_dir):\n",
        "    \"\"\"\n",
        "    Saves images from the specified page of the PDF to a directory.\n",
        "\n",
        "    Args:\n",
        "        pdf_file (str): Path to the PDF file.\n",
        "        page_index (int): Page index (0-based).\n",
        "        output_dir (str): Directory to save extracted images.\n",
        "\n",
        "    Returns:\n",
        "        list: Paths to the saved images.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        image_paths = []\n",
        "        with fitz.open(pdf_file) as pdf:\n",
        "            if not (0 <= page_index < len(pdf)):\n",
        "                return []\n",
        "            page = pdf[page_index]\n",
        "            for img_index, img in enumerate(page.get_images(full=True)):\n",
        "                xref = img[0]\n",
        "                base_image = pdf.extract_image(xref)\n",
        "                image_bytes = base_image[\"image\"]\n",
        "                img_path = os.path.join(output_dir, f\"page_{page_index + 1}_img{img_index + 1}.png\")\n",
        "                with open(img_path, \"wb\") as img_file:\n",
        "                    img_file.write(image_bytes)\n",
        "                image_paths.append(img_path)\n",
        "        return image_paths\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error extracting images: {e}\" + Style.RESET_ALL)\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "IyeK92OrMxY0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_query_for_pages(query):\n",
        "    \"\"\"\n",
        "    Parses a user query to extract requested page numbers.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query string (e.g., \"Extract page 1 and page 3\").\n",
        "\n",
        "    Returns:\n",
        "        list: List of page indices (0-based).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return [int(word) - 1 for word in query.split() if word.isdigit()]\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Invalid query format. Ensure page numbers are specified correctly.\")\n"
      ],
      "metadata": {
        "id": "DARYbQMVM2z5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_page(pdf_file, page_index, image_dir):\n",
        "    \"\"\"\n",
        "    Extracts and processes data from a single PDF page.\n",
        "\n",
        "    Args:\n",
        "        pdf_file (str): Path to the PDF file.\n",
        "        page_index (int): Page index (0-based).\n",
        "        image_dir (str): Directory to save extracted images.\n",
        "\n",
        "    Returns:\n",
        "        str: Processed results including text, tables, and image paths.\n",
        "    \"\"\"\n",
        "    result = f\"\\n{Fore.YELLOW}--- Page {page_index + 1} Data ---{Style.RESET_ALL}\\n\"\n",
        "\n",
        "    text, tables = fetch_text_and_tables(pdf_file, page_index)\n",
        "    if text:\n",
        "        result += f\"\\n{Fore.GREEN}Text Content:\\n{text}{Style.RESET_ALL}\\n\"\n",
        "    else:\n",
        "        result += f\"\\n{Fore.RED}No text found on this page.{Style.RESET_ALL}\\n\"\n",
        "\n",
        "    if tables:\n",
        "        result += f\"\\n{Fore.CYAN}Tables:\\n{Style.RESET_ALL}\"\n",
        "        for table in tables:\n",
        "            for row in table:\n",
        "                result += \" | \".join(str(cell) for cell in row) + \"\\n\"\n",
        "    else:\n",
        "        result += f\"\\n{Fore.RED}No tables found.{Style.RESET_ALL}\\n\"\n",
        "\n",
        "    images = save_images_from_page(pdf_file, page_index, image_dir)\n",
        "    if images:\n",
        "        result += f\"\\n{Fore.BLUE}Images saved:\\n{Style.RESET_ALL}\"\n",
        "        result += \"\\n\".join(images) + \"\\n\"\n",
        "    else:\n",
        "        result += f\"\\n{Fore.RED}No images found on this page.{Style.RESET_ALL}\\n\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "zElAnVGiM6gV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(pdf_file, query, image_dir):\n",
        "    \"\"\"\n",
        "    Processes a user query to extract data from specified PDF pages.\n",
        "\n",
        "    Args:\n",
        "        pdf_file (str): Path to the PDF file.\n",
        "        query (str): User query specifying pages.\n",
        "        image_dir (str): Directory to save extracted images.\n",
        "\n",
        "    Returns:\n",
        "        str: Consolidated extraction results.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        page_indices = parse_query_for_pages(query)\n",
        "        if not page_indices:\n",
        "            return f\"{Fore.RED}No valid pages specified.{Style.RESET_ALL}\"\n",
        "\n",
        "        results = \"\"\n",
        "        for page_index in page_indices:\n",
        "            results += process_page(pdf_file, page_index, image_dir)\n",
        "        return results\n",
        "    except ValueError as e:\n",
        "        return f\"{Fore.RED}Error: {e}{Style.RESET_ALL}\""
      ],
      "metadata": {
        "id": "Gc_ff5yaM7YE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    pdf_path = \"/content/NLP.pdf\"\n",
        "    img_dir = \"extracted_images\"\n",
        "\n",
        "    print(Fore.BLUE + \"Welcome to the Enhanced PDF Extractor!\" + Style.RESET_ALL)\n",
        "    print(\"Extract text, tables, and images from specific pages.\")\n",
        "\n",
        "    user_query = input(Fore.YELLOW + \"Enter your query: \" + Style.RESET_ALL)\n",
        "    extraction_results = process_query(pdf_path, user_query, img_dir)\n",
        "\n",
        "    print(Fore.GREEN + \"\\n--- Extraction Results ---\\n\" + Style.RESET_ALL)\n",
        "    print(extraction_results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itak9NNHM9t0",
        "outputId": "c65eb369-09bd-4cbe-da35-af99c3215c2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mWelcome to the Enhanced PDF Extractor!\u001b[0m\n",
            "Extract text, tables, and images from specific pages.\n",
            "\u001b[33mEnter your query: \u001b[0mpage 2\n",
            "\u001b[32m\n",
            "--- Extraction Results ---\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[33m--- Page 2 Data ---\u001b[0m\n",
            "\n",
            "\u001b[32mText Content:\n",
            "Ans: Machine Translation (MT) is the task of automatically\n",
            "converting one natural language into another, preserving the meaning\n",
            "of the input text, and producing fluent text in the output language.\n",
            "[6] Applications of Nlp\n",
            "Ans: Natural Language Processing is a cross among many different\n",
            "fields such as:\n",
            "• Sentiment Analysis.\n",
            "• Text Classification.\n",
            "• Chatbots & Virtual Assistants.\n",
            "• Text Extraction.\n",
            "• Machine Translation.\n",
            "• Text Summarization.\n",
            "• Market Intelligence.\n",
            "• Auto-Correct.\n",
            "[7] Text Coherence\n",
            "Ans: Coherence is a key property of any well-organized text. It\n",
            "evaluates the degree of logical consistency for text and can help\n",
            "document a set of sentences into a logically consistent order, which is\n",
            "at the core of many text-synthesis tasks such as text generation and\n",
            "multi- document summarization.\n",
            "[8] Sentiment Analysis or Opinion mining\n",
            "Ans:Sentiment analysis (or opinion mining) is a natural language\n",
            "processing (NLP) technique used to determine whether data is\n",
            "positive, negative or neutral.\n",
            "Sentiment analysis is often performed on textual data to help\n",
            "businesses monitor brand and product sentiment in customer\n",
            "feedback, and understand customer needs.\n",
            "[9] Semantic role labelling\n",
            "Ans: In natural language processing, semantic role labeling (also\n",
            "called shallow semantic parsing or slot-filling) is the process that\u001b[0m\n",
            "\n",
            "\u001b[31mNo tables found.\u001b[0m\n",
            "\n",
            "\u001b[31mNo images found on this page.\u001b[0m\n",
            "\n"
          ]
        }
      ]
    }
  ]
}